#!/usr/bin/env node

/**
 * Test script for upsert functionality
 * Tests MERGE operations with composite primary key
 */

const { BigQuery } = require('@google-cloud/bigquery');

async function testUpsertFunctionality() {
  console.log('ğŸ§ª Testing Upsert Functionality...\n');

  try {
    // Initialize BigQuery client
    const projectId = process.env.GOOGLE_CLOUD_PROJECT || 'dev-epsilon-467101-v2';
    const datasetId = process.env.BIGQUERY_DATASET || 'direction_sky_data';
    
    const bigquery = new BigQuery({
      projectId: projectId,
      keyFilename: process.env.GOOGLE_APPLICATION_CREDENTIALS
    });

    // Test 1: Insert initial data
    console.log('ğŸ“ Test 1: Inserting initial data via MERGE...');
    const initialData = {
      timestamp: new Date().toISOString(), // Convert to ISO string
      underlying_asset: 'UPSERT_TEST',
      contract_id: 'UPSERT240119C00100000',
      contract_type: 'call',
      strike_price: 100.0,
      expiration_date: '2024-01-19',
      bid: 2.00,
      ask: 2.10,
      volume: 200,
      open_interest: 1000,
      score: 90.0,
      created_at: new Date().toISOString() // Convert to ISO string
    };

    // Use MERGE to insert (this is what our upsert method does)
    const insertQuery = `
      MERGE \`${projectId}.${datasetId}.polygon_options\` AS target
      USING (
        SELECT 
          ? as timestamp,
          ? as underlying_asset,
          ? as contract_id,
          ? as contract_type,
          ? as strike_price,
          ? as expiration_date,
          ? as bid,
          ? as ask,
          ? as volume,
          ? as open_interest,
          ? as score,
          ? as created_at
      ) AS source
      ON target.contract_id = source.contract_id AND target.timestamp = TIMESTAMP(source.timestamp)
      WHEN NOT MATCHED THEN
        INSERT (timestamp, underlying_asset, contract_id, contract_type, strike_price, expiration_date, bid, ask, volume, open_interest, score, created_at)
        VALUES (TIMESTAMP(source.timestamp), source.underlying_asset, source.contract_id, source.contract_type, source.strike_price, DATE(source.expiration_date), source.bid, source.ask, source.volume, source.open_interest, source.score, TIMESTAMP(source.created_at))
    `;

    const insertJobConfig = {
      query: insertQuery,
      params: [
        initialData.timestamp,
        initialData.underlying_asset,
        initialData.contract_id,
        initialData.contract_type,
        initialData.strike_price,
        initialData.expiration_date,
        initialData.bid,
        initialData.ask,
        initialData.volume,
        initialData.open_interest,
        initialData.score,
        initialData.created_at
      ]
    };

    await bigquery.query(insertJobConfig);
    console.log('âœ… Initial data inserted via MERGE');

    // Test 2: Update existing data via MERGE (upsert)
    console.log('\nğŸ“ Test 2: Updating existing data via MERGE (upsert)...');
    const updatedData = {
      ...initialData,
      bid: 2.25,  // Updated bid
      ask: 2.35,  // Updated ask
      volume: 300, // Updated volume
      score: 95.0  // Updated score
    };

    const updateQuery = `
      MERGE \`${projectId}.${datasetId}.polygon_options\` AS target
      USING (
        SELECT 
          ? as timestamp,
          ? as underlying_asset,
          ? as contract_id,
          ? as contract_type,
          ? as strike_price,
          ? as expiration_date,
          ? as bid,
          ? as ask,
          ? as volume,
          ? as open_interest,
          ? as score,
          ? as created_at
      ) AS source
      ON target.contract_id = source.contract_id AND target.timestamp = TIMESTAMP(source.timestamp)
      WHEN MATCHED THEN
        UPDATE SET
          bid = source.bid,
          ask = source.ask,
          volume = source.volume,
          score = source.score
      WHEN NOT MATCHED THEN
        INSERT (timestamp, underlying_asset, contract_id, contract_type, strike_price, expiration_date, bid, ask, volume, open_interest, score, created_at)
        VALUES (TIMESTAMP(source.timestamp), source.underlying_asset, source.contract_id, source.contract_type, source.strike_price, DATE(source.expiration_date), source.bid, source.ask, source.volume, source.open_interest, source.score, TIMESTAMP(source.created_at))
    `;

    const updateJobConfig = {
      query: updateQuery,
      params: [
        updatedData.timestamp,
        updatedData.underlying_asset,
        updatedData.contract_id,
        updatedData.contract_type,
        updatedData.strike_price,
        updatedData.expiration_date,
        updatedData.bid,
        updatedData.ask,
        updatedData.volume,
        updatedData.open_interest,
        updatedData.score,
        updatedData.created_at
      ]
    };

    await bigquery.query(updateJobConfig);
    console.log('âœ… Data updated via MERGE (upsert)');

    // Test 3: Verify the update worked
    console.log('\nğŸ“ Test 3: Verifying the update...');
    const verifyQuery = `
      SELECT 
        contract_id,
        timestamp,
        bid,
        ask,
        volume,
        score
      FROM \`${projectId}.${datasetId}.polygon_options\`
      WHERE contract_id = 'UPSERT240119C00100000'
      ORDER BY timestamp DESC
      LIMIT 1
    `;

    const [verifyResults] = await bigquery.query({ query: verifyQuery });
    
    if (verifyResults.length > 0) {
      const row = verifyResults[0];
      console.log('âœ… Data verification successful');
      console.log('ğŸ“Š Updated values:');
      console.log(`  Bid: $${row.bid} (was $2.00)`);
      console.log(`  Ask: $${row.ask} (was $2.10)`);
      console.log(`  Volume: ${row.volume} (was 200)`);
      console.log(`  Score: ${row.score} (was 90.0)`);
      
      // Check if values were actually updated
      if (row.bid === 2.25 && row.ask === 2.35 && row.volume === 300 && row.score === 95.0) {
        console.log('âœ… All values updated correctly via upsert');
      } else {
        console.log('âŒ Some values were not updated correctly');
      }
    } else {
      console.log('âŒ No data found after update');
    }

    // Test 4: Check for duplicates
    console.log('\nğŸ“ Test 4: Checking for duplicates...');
    const duplicateQuery = `
      SELECT 
        contract_id,
        timestamp,
        COUNT(*) as count
      FROM \`${projectId}.${datasetId}.polygon_options\`
      WHERE contract_id = 'UPSERT240119C00100000'
      GROUP BY contract_id, timestamp
      HAVING COUNT(*) > 1
    `;

    const [duplicateResults] = await bigquery.query({ query: duplicateQuery });
    
    if (duplicateResults.length === 0) {
      console.log('âœ… No duplicates found - composite primary key working correctly');
    } else {
      console.log('âŒ Found duplicates:');
      duplicateResults.forEach(row => {
        console.log(`  ${row.contract_id} at ${row.timestamp}: ${row.count} records`);
      });
    }

    console.log('\nğŸ‰ Upsert Test Completed Successfully!');
    console.log('\nğŸ“‹ Summary:');
    console.log('  âœ… MERGE operations work correctly');
    console.log('  âœ… Updates are applied via upsert');
    console.log('  âœ… No duplicate records created');
    console.log('  âœ… Composite primary key constraint is enforced');

  } catch (error) {
    console.error('\nâŒ Test failed:', error.message);
    console.error('Stack trace:', error.stack);
    process.exit(1);
  }
}

// Run the test
if (require.main === module) {
  testUpsertFunctionality();
}

module.exports = { testUpsertFunctionality }; 